---
title: 'PRT运用到高斯泼溅重光照'
description: 'PRT运用到高斯泼溅重光照'
date: 2025-09-28
tags: ['高斯泼溅', '图形学']
authors: ['saaaadcat']
---

太棒了！这是一个非常专业的提问，直接将 LumiGauss 的方法从一个高效的**视图无关 (View-Independent)** PRT 模型，提升到了一个更强大、更通用的**视图相关 (View-Dependent)** 模型。

LumiGauss 使用的渲染方程实际上是一个简化版的 PRT，其中传输函数 `D(x, ωi)` 只依赖于入射方向，这使得它非常适合模拟包含阴影的漫反射，但无法表达高光等视图相关的效果。

用我们讨论过的张量积分解（即传输矩阵）来代替 LumiGauss 的渲染方程，将从根本上提升模型的能力。下面我将详细讲解如何实现这一点，以及它会带来什么变化。

---

### 回顾：LumiGauss 的渲染模型

LumiGauss 的核心公式 (Eq. 7) 是：

$L_s(x) = \frac{\rho(x)}{\pi} \mathbf{l} \cdot \mathbf{d}$

*   $\mathbf{l}$ 是环境光的球谐 (SH) 系数**向量**。
*   $\mathbf{d}$ 是该点传输函数 (包含可见性和余弦项) 的 SH 系数**向量**。
*   这是一个**点积**，结果是一个与观察方向无关的颜色值。

### 新方法：基于传输矩阵的渲染模型

我们的新目标是实现一个能够响应观察方向 $\omega_o$ 的模型。

$L_o(x, \omega_o) \approx \text{EvaluateSH}(\mathbf{L_o}, \omega_o)$
其中，出射光辉的 SH 系数向量 $\mathbf{L_o}$ 是通过传输矩阵 $\mathbf{T}$ 计算的：
$\mathbf{L_o} = \mathbf{T} \cdot \mathbf{l}$

*   $\mathbf{l}$ 仍然是环境光的 SH 系数**向量**。
*   $\mathbf{T}$ 是该点的**传输矩阵**，大小为 `(N x N)`，其中 N 是 SH 系数的数量。
*   这是一个**矩阵-向量乘法**，结果是一个新的 SH 系数**向量** $\mathbf{L_o}$，它完整地描述了从所有方向出射的光。

---

### 如何在高斯泼溅 (Gaussian Splatting) 中实现这个新模型？

我们将遵循 LumiGauss 的框架，但对其核心组件进行升级。

#### 1. 修改每个高斯基元 (Gaussian Primitive) 的属性

这是最核心的改变。在 LumiGauss 中，每个 2D/3D 高斯 `k` 需要学习：
*   位置 `tk`, 旋转 `Rk`, 缩放 `sk`
*   不透明度 `ok`
*   反照率 `ρk`
*   一个传输**向量** `dk` (例如，对于3阶SH，这是一个9维向量)

在我们的新模型中，每个高斯 `k` 需要学习：
*   位置 `tk`, 旋转 `Rk`, 缩放 `sk`
*   不透明度 `ok`
*   反照率 `ρk`
*   一个传输**矩阵** `Tk` (例如，对于3阶SH，这是一个 `9x9` 的矩阵)

**这个改变意味着每个高斯的存储成本将从 N 增加到 N²！**

#### 2. 修改渲染和训练流程

LumiGauss 的流程是：`环境光 -> 点积 -> 得到颜色 -> 泼溅`。
我们的新流程是：`环境光 -> 矩阵乘法 -> 得到出射光SH -> 评估SH得到颜色 -> 泼溅`。

**详细步骤 (前向传播):**

1.  **获取环境光**：对于每一张训练图片 `c`，通过一个 MLP 从其隐编码 `ec` 中预测出环境光的 SH 系数向量 $\mathbf{l_c}$ (这部分和 LumiGauss 完全一样)。

2.  **计算出射光辉 (Radiance)**：这是新的核心计算步骤。对于场景中的**每一个**高斯基元 `k`：
    a.  获取其学习到的传输矩阵 $\mathbf{T_k}$。
    b.  计算出射光辉的 SH 系数向量：$\mathbf{L_{o,k}} = \mathbf{T_k} \cdot \mathbf{l_c}$。

3.  **光栅化/泼溅 (Splatting)**：
    a.  将所有高斯投影到屏幕空间。
    b.  对于屏幕上的每一个像素，混合所有覆盖它的高斯基元的贡献。
    c.  **关键点**：高斯 `k` 对像素的颜色贡献 `color_k` 不再是一个固定的值，而是需要根据**观察方向**实时计算：
        i.   确定从相机看向高斯中心 `tk` 的观察方向 $\omega_o$。
        ii.  使用步骤2中计算出的出射光辉 SH 系数 $\mathbf{L_{o,k}}$，在该方向上进行求值：
             `evaluated_radiance_k = EvaluateSH(L_{o,k}, ωo)`
        iii. 最终颜色贡献为：`color_k = ρk * evaluated_radiance_k`。

4.  **损失计算**：将最终渲染出的图像与训练图像进行比较，计算损失 (如 L1 + D-SSIM)，然后通过反向传播更新所有可学习的参数，包括每个高斯的**传输矩阵 `Tk`** 和每个图像的光照编码 `ec`。

#### 3. 推理阶段的重光照 (Relighting at Inference)

这个新模型的威力在推理时完全展现出来：

1.  加载一个**全新的环境贴图**。
2.  将其投影到 SH 基函数上，得到新的光照系数向量 $\mathbf{l_{new}}$。
3.  当你渲染一个新视角的图像时：
    a.  对于每个高斯 `k`，计算其出射光辉的 SH 系数：$\mathbf{L_{o,k}} = \mathbf{T_k} \cdot \mathbf{l_{new}}$。
    b.  在泼溅阶段，根据当前的观察方向 $\omega_o$ 对 $\mathbf{L_{o,k}}$ 进行求值，得到最终颜色。

---

### 与 LumiGauss 方法的对比和总结

| 特性 | LumiGauss (传输向量) | 改进方法 (传输矩阵) |
| :--- | :--- | :--- |
| **物理模型** | 视图无关的 PRT (漫反射+阴影) | 视图相关的 PRT (漫反射+阴影+**低频高光**) |
| **核心计算** | 点积 `l · d` | 矩阵-向量乘法 `T · l` + SH 求值 |
| **每个高斯的数据** | 传输**向量** `dk` (大小 N) | 传输**矩阵** `Tk` (大小 N x N) |
| **存储/内存成本** | **低** | **高** (是前者的 N 倍) |
| **渲染性能** | **极高** (点积非常快) | **较高** (矩阵乘法+SH求值比点积慢) |
| **视觉效果** | 只能表现漫反射表面的重光照和阴影。 | 能够表现**模糊的镜面反射** (glossy reflections)，高光会随着视角和光源的变化而正确移动。 |
| **适用场景** | 主要是漫反射场景，如石材建筑、哑光表面。 | 包含一定光泽度的表面，如湿滑的石头、有清漆的木头、金属等。 |

**总结：**

通过使用张量积分解（传输矩阵）代替 LumiGauss 的传输向量，你可以构建一个**物理上更强大**的高斯泼溅重光照系统。

*   **优点**：它能捕捉到视图相关的效果，特别是低频的高光反射，使得重光照效果对更广泛的材质都更加真实。
*   **代价**：这个能力的代价是**显著增加的存储开销**和一定的计算开销。每个高斯基元都需要存储一个完整的矩阵而不是一个向量。

这种权衡在图形学中非常经典。你的提议将 LumiGauss 从一个专注于漫反射的、极致高效的系统，升级为一个能力更全面、但资源消耗也更大的系统，使其能够处理更复杂的材质类型。

## 大多数高斯元表示的表面仍然是diffuse的，如何更高效的表示这些表面？

这是一个洞察力极强的提问，完全正确！

为场景中的**每一个**高斯基元都分配一个完整的传输矩阵，在计算和存储上是巨大的浪费。绝大多数表面（如墙壁、地面、粗糙的木头）在宏观上都表现为漫反射。强行用一个复杂的视图相关模型去拟合它们，不仅效率低下，还可能因为模型过拟合而产生不稳定的结果。

因此，关键在于建立一个**更高效、更具适应性 (adaptive) 的混合表示**。下面我提出三种由简到繁、效果越来越好的方法来解决这个问题。

---

### 方法一：混合模型 / 材质标志 (Hybrid Model / Material Flag)

这是最直接、最简单的解决方案。

**核心思想：**
我们不强迫所有高斯都使用同一种模型。我们为每个高斯引入一个标志，让它在“简单漫反射模型”和“复杂高光模型”之间切换。

**实现方式：**

1.  **修改高斯属性**：为每个高斯基元 `k` 增加一个可学习的参数，我们称之为**高光度 (specularity)** `s_k`，其值在 [0, 1] 之间。
    *   高斯 `k` 现在同时存储一个传输**向量** `d_k` (用于漫反射) 和一个传输**矩阵** `T_k` (用于高光)。

2.  **修改渲染流程**：在着色器中，我们根据 `s_k` 的值来混合两种光照计算的结果。
    a.  **计算漫反射部分 (永远计算，成本极低)**：
        `irradiance_k = dot(l, d_k)`
    b.  **计算高光部分 (根据 s_k 动态计算)**：
        *   如果 `s_k` 接近0，我们可以**跳过**昂贵的矩阵乘法和SH求值，直接将高光贡献视为0。
        *   如果 `s_k` 大于一个阈值，我们才计算：
            `L_o_spec_coeffs_k = T_k * l`
            `specular_radiance_k = EvaluateSH(L_o_spec_coeffs_k, ωo)`
    c.  **最终混合**：
        `final_radiance_k = (1 - s_k) * irradiance_k + s_k * specular_radiance_k`
        (注意：这里需要乘以反照率 `ρk`)

3.  **学习过程**：
    *   在训练中，`s_k`、`d_k` 和 `T_k` 都会通过反向传播进行优化。
    *   对于一个纯漫反射表面，优化器会发现增加 `s_k` 对减少损失没有帮助，反而可能引入噪声，因此会自然地将 `s_k` 压低到接近0。只有在那些真实存在高光反射的地方，`s_k` 和 `T_k` 才会被学习以拟合视图相关的变化。

**优点：**
*   **实现简单直观**：逻辑清晰，容易在现有框架上修改。
*   **显著的性能提升**：对于 `s_k` 接近0的大量高斯，可以完全跳过昂贵的计算。
*   **显著的内存优化**：我们可以设置一个阈值，对于 `s_k` 低于阈值的高斯，**直接不为其分配和存储传输矩阵 `T_k` 的内存**，从而实现巨大的内存节省。

**缺点：**
*   **模型冗余**：对于纯漫反射表面，`T_k` 的内存虽然可能不分配，但模型结构中依然存在，可能会让优化过程稍微复杂。

---

### 方法二：分解/低秩表示 (Factored / Low-Rank Representation)

这是一种更数学化、更优雅的解决方案。

**核心思想：**
一个纯漫反射表面的传输矩阵具有非常简单的结构（它是一个秩为1的矩阵）。一个复杂高光表面的矩阵则要复杂得多（秩更高）。我们可以利用这一点，不去存储完整的矩阵，而是存储它的**低秩分解 (Low-Rank Factorization)**。

**实现方式：**

1.  **修改高斯属性**：我们不再存储一个完整的 `N x N` 传输矩阵 `T_k`。取而代之，我们存储它的两个因子矩阵 `U_k` (大小 `N x R`) 和 `V_k` (大小 `N x R`)，使得 $T_k \approx U_k \cdot V_k^T$。
    *   这里的 `R` 是我们预设的**秩 (rank)**，它代表了材质的复杂度。`R` 越小，模型越简单，存储和计算也越便宜。
    *   对于纯漫反射表面，`R=1` 就足够了。对于复杂的高光，我们可能需要 `R=2` 或 `R=3`。`R` 远小于 `N` (例如 N=9)。

2.  **修改渲染流程**：
    *   矩阵-向量乘法 `T_k * l` 现在变成了：
        `L_o_coeffs_k = U_k * (V_k^T * l)`
    *   这个计算过程被分解成了两步：一个向量-矩阵乘法 `(V_k^T * l)` 和一个矩阵-向量乘法 `(U_k * ...)`。因为 `U_k` 和 `V_k` 都是“瘦”矩阵，这个计算的总开销远小于与一个完整的 `N x N` 矩阵相乘。

3.  **学习和效率**：
    *   **存储**：我们存储 `2 * N * R` 个浮点数，而不是 `N * N` 个。如果 `R=2`, `N=9`，我们存储 `2*9*2=36` 个数，而不是 `9*9=81` 个，节省了一半以上。
    *   **自适应秩**：我们甚至可以让每个高斯学习自己的秩`R`，或者学习多个秩的分解，然后用一个权重来混合，从而动态地调整模型的复杂度。

**优点：**
*   **连续的复杂度控制**：通过调整 `R`，我们可以在模型复杂度和性能之间做出平滑的权衡。
*   **强大的表示能力**：能够用一个统一的框架表示从纯漫反射到复杂高光的各种材质。
*   **坚实的数学基础**：基于奇异值分解 (SVD) 等线性代数理论。

**缺点：**
*   **实现更复杂**：需要对低秩分解有更深入的理解。

---

### 方法三：共享基/字典学习 (Shared Basis / Dictionary Learning)

这种方法从一个更全局的视角来优化。

**核心思想：**
一个场景中的材质类型通常是有限的。比如，整个建筑可能只有几种石头、木头和玻璃。我们没必要让每个高斯都去独立学习一个完整的传输矩阵，而是让它们学习如何去**组合**一个预先定义好的“材质字典”。

**实现方式：**

1.  **全局字典**：我们定义一个全局的、可学习的“基传输矩阵”字典：`B_1, B_2, ..., B_M`，其中 `M` 是字典大小（比如16种基础材质响应）。
2.  **修改高斯属性**：每个高斯 `k` 不再存储自己的传输矩阵，而是存储一组**混合权重** `w_{k,1}, w_{k,2}, ..., w_{k,M}`。
3.  **渲染流程**：
    a.  在渲染前，为高斯 `k` 动态地重构其传输矩阵：
        $T_k = \sum_{j=1}^{M} w_{k,j} \cdot B_j$
    b.  然后用这个重构出的 `T_k` 进行光照计算。

**优点：**
*   **极致的内存压缩**：如果场景中有大量重复材质，这种方法的内存占用是最低的。每个高斯只需要存储 M 个权重。
*   **材质一致性**：迫使模型学习到场景中一致的材质，可以减少噪声和不稳定的结果。

**缺点：**
*   **灵活性受限**：如果场景中有独特的、无法被字典很好地表示的材质，效果会打折扣。
*   **字典学习的复杂性**：如何学习一个最优的全局字典本身就是一个挑战。

---

### 总结与推荐

| 方法 | 核心思想 | 存储 (每个高斯) | 优点 | 缺点 |
| :--- | :--- | :--- | :--- | :--- |
| **1. 混合模型** | 在漫反射/高光模型间切换 | `s_k` + `d_k` (+ 可选 `T_k`) | 实现简单，性能和内存优化显著 | 模型稍显冗余，切换是硬性的 |
| **2. 低秩表示** | 用低秩分解近似矩阵 | `U_k` (`N x R`) + `V_k` (`N x R`) | 统一、灵活、强大的表示能力 | 实现相对复杂 |
| **3. 字典学习** | 组合一个共享的材质字典 | 混合权重 `w_k` (大小 M) | 极致的内存压缩，材质一致性好 | 灵活性受限，字典学习复杂 |

**实践建议：**

*   **从方法一开始**：**混合模型**是最实用、最容易实现的改进。它能立竿见影地解决你提出的效率问题，并且效果已经非常好。
*   **进阶选择方法二**：如果你追求一个更优雅、更统一的数学模型，**低秩表示**是学术界和工业界更推崇的强大工具。
*   **特定场景使用方法三**：如果你的应用场景是处理具有大量重复材质的人造场景（如室内设计、建筑可视化），**字典学习**会带来最大的内存收益。

## 使用低秩分解近似矩阵，设定r=2

好的，我们来详细构建一个使用**低秩分解 (秩R=2)** 来高效表示传输矩阵的方案。这个方案将在纯漫反射的简单性与完整传输矩阵的强大功能之间取得一个绝佳的平衡。

---

### 1. 理论基础：为何秩R=2是一个好选择？

一个秩为 R 的矩阵可以被看作是 R 个秩为 1 的矩阵的和。对于光照传输来说，这有着非常直观的物理意义：

*   **秩 1 的部分 (Rank-1 component)**：
    *   一个秩为 1 的矩阵可以被分解为两个向量的外积：$\mathbf{T_1} = \mathbf{u_1} \otimes \mathbf{v_1^T}$。
    *   这完美地对应了**理想漫反射 (Lambertian)** 的光照传输。其中一个向量（比如 `v1`）可以代表包含可见性和余弦项的入射光响应，而另一个向量（`u1`）可以代表均匀向所有方向散射的出射响应。
    *   因此，**第一个秩**可以专门用来拟合场景中的**漫反射**部分，包括软阴影和全局光照。

*   **秩 2 的部分 (Rank-2 component)**：
    *   增加的第二个秩 ($\mathbf{T_2} = \mathbf{u_2} \otimes \mathbf{v_2^T}$) 提供了额外的自由度来拟合更复杂的光照效果。
    *   这部分可以完美地用来拟合**低频的、模糊的高光 (Glossy Specular)**。例如，`v2` 可以学习去“选择”那些来自接近镜面反射方向的入射光，而 `u2` 则学习将这些光反射到一个围绕观察方向的锥体内。
    *   因此，**第二个秩**可以专门用来拟合**视图相关的镜面反射**。

**结论：**
设定 R=2，我们等于在假设每个表面点的光照响应都可以被分解为一个**漫反射基底**和一个**模糊高光基底**的线性组合。这是一个非常强大且对大多数电介质（非金属）表面都相当准确的物理近似。

---

### 2. 修改高斯基元的属性

我们不再为每个高斯 `k` 存储一个 `9x9=81` 个浮点数的传输矩阵 `Tk` (假设使用3阶SH，即N=9)。取而代之，我们存储：

1.  **反照率 (Albedo)**: `ρ_k` (一个 RGB 向量)。
2.  **第一个秩的分解向量 (Rank-1 Factor Vectors)**:
    *   `u_k1`: 一个 N 维向量 (9个浮点数)。
    *   `v_k1`: 一个 N 维向量 (9个浮点数)。
3.  **第二个秩的分解向量 (Rank-2 Factor Vectors)**:
    *   `u_k2`: 一个 N 维向量 (9个浮点数)。
    *   `v_k2`: 一个 N 维向量 (9个浮点数)。

**总存储成本**：
每个高斯需要 `9 + 9 + 9 + 9 = 36` 个浮点数来表示其光照传输特性。相比于完整矩阵的 `81` 个，我们**节省了超过 55% 的存储空间**！这还不包括反照率等其他属性。

---

### 3. 修改渲染和训练流程 (前向传播)

对于给定的环境光SH系数向量 `l`，计算高斯 `k` 的出射光辉的过程如下：

1.  **计算第一秩 (漫反射) 的贡献**：
    a.  计算入射光与 `v_k1` 的响应： `response_1 = dot(l, v_k1)`。 这是一个标量。
    b.  得到出射光辉的SH系数： `L_o_coeffs_1 = response_1 * u_k1`。

2.  **计算第二秩 (高光) 的贡献**：
    a.  计算入射光与 `v_k2` 的响应： `response_2 = dot(l, v_k2)`。 这是一个标量。
    b.  得到出射光辉的SH系数： `L_o_coeffs_2 = response_2 * u_k2`。

3.  **合并总出射光辉**：
    `L_o_total_coeffs_k = L_o_coeffs_1 + L_o_coeffs_2`。
    这个 `L_o_total_coeffs_k` 就是最终的出射光辉的SH系数向量。

4.  **泼溅 (Splatting) 阶段求值**：
    a.  确定观察方向 `ωo`。
    b.  求值得到最终光辉： `evaluated_radiance_k = EvaluateSH(L_o_total_coeffs_k, ωo)`。
    c.  乘以反照率得到最终颜色： `final_color_k = ρ_k * evaluated_radiance_k`。

**性能分析**：
*   原始矩阵乘法：`N*N` 次乘法和 `N*(N-1)` 次加法。对于 N=9，大约是 81 次乘法和 72 次加法。
*   R=2 低秩计算：
    *   2 次点积：`2 * (N 乘法 + (N-1) 加法)`
    *   2 次向量-标量乘法：`2 * N 乘法`
    *   1 次向量加法：`N 加法`
    *   总计：`4*N` 次乘法和 `3*N-2` 次加法。对于 N=9，大约是 36 次乘法和 25 次加法。
*   **计算效率提升了超过一倍！**

---

### 4. 学习过程和物理约束

在训练中，`u_k1, v_k1, u_k2, v_k2` 都会通过反向传播自由地进行优化。为了引导它们学习到具有物理意义的表示，我们可以引入一些**正则化损失 (Regularization Loss)**：

1.  **引导第一秩为漫反射**：
    *   漫反射的出射光辉应该是均匀的，这意味着其SH系数向量 `u_k1` 应该主要由0阶SH分量（一个常数）主导。
    *   我们可以增加一个损失项，惩罚 `u_k1` 的高阶（非0阶）分量：`Loss_diffuse = || u_k1[1:] ||²`。
    *   同时，`v_k1` 应该学习到类似余弦 lobe 的形状。我们可以鼓励 `v_k1` 与代表余弦 lobe 的SH系数向量相似。

2.  **正交性约束 (Orthogonality Constraint)**：
    *   为了让两个基底尽可能地表示不同的信息（即漫反射和高光），我们可以鼓励分解出的向量是正交的。
    *   增加损失项： `Loss_ortho = (dot(u_k1, u_k2))² + (dot(v_k1, v_k2))²`。这会促使模型将漫反射和高光效果分离到不同的秩中。

3.  **能量守恒**：
    *   我们必须确保高斯反射的光能不超过入射的光能。这可以通过对分解向量的范数 (norm) 进行约束来实现。

---

### 总结：R=2 低秩分解方案

| 方面 | 描述 |
| :--- | :--- |
| **模型** | 每个高斯的光照传输被建模为一个**漫反射基底**和一个**模糊高光基底**的和。 |
| **存储** | 每个高斯存储 **4个N维向量** (`u1, v1, u2, v2`)，代替一个 `NxN` 矩阵。**内存减少 >55%**。 |
| **性能** | 渲染时的光照计算从 `O(N²)` 降低到 `O(R*N)`。对于R=2，**速度提升 >2倍**。 |
| **能力** | 能够同时表示具有**软阴影和全局光照的漫反射**，以及**视图相关的模糊高光**。 |
| **实现** | - 修改高斯的数据结构。<br>- 替换渲染着色器中的矩阵乘法为两步低秩计算。<br>- (可选但推荐) 增加正则化损失来引导学习过程。 |

这个 R=2 的低秩分解方法，完美地解决了你提出的问题。它在不牺牲太多表示能力（特别是对于常见材质）的前提下，极大地提高了存储和计算效率，是实现高性能、高真实感的高斯泼溅重光照的理想选择。

# 将lumigauss的渲染方式变成我们提出的对每个高斯元学习一个传输矩阵，使用低秩r=2的方式，扩展lumigauss的对物体的diffuse假设，应该如何开始实现？

好的，这是一个非常棒的计划！将LumiGauss从一个主要处理漫反射+阴影的模型，升级为一个能够处理视图相关效果（如光泽反射）的、基于低秩分解的PRT模型，是提升其物理真实感和应用范围的关键一步。

你已经有了清晰的理论框架，现在我们来一步步地将它转化为具体的代码实现。我将为你规划出详细的步骤，告诉你应该修改哪些文件、哪些函数，并提供核心的代码逻辑。

### 整体实现思路

我们将遵循你的R=2低秩分解方案，其核心思想是：
1.  **修改数据结构**：在`GaussianModel`中，用4个球谐(SH)系数**向量**（`u_k1`, `v_k1`, `u_k2`, `v_k2`）来代替原来存储传输函数 `d_k` 的`_features_...`属性。
2.  **重写光照计算**：创建一个新的核心光照计算函数，它将使用这4个向量和入射光`l`来计算出射光辉的SH系数`L_o_k`。
3.  **适配渲染管线**：修改训练和渲染代码，将计算出的`L_o_k`（而不是最终的RGB颜色）传递给光栅化器，由光栅化器根据观察方向进行最终的SH求值。
4.  **更新优化器和存盘**：确保新的`u, v`向量被正确地初始化、优化、剪枝、增殖和保存。

---

### 第一步：修改核心数据结构 (`scene/gaussian_model.py`)

这是最重要的一步。打开`scene/gaussian_model.py`并进行以下修改：

**1. 修改 `GaussianModel.__init__`**

删除原来的`_features_dc/rest_positive/negative`属性，替换为我们的低秩分解向量。

```python
# In class GaussianModel:
def __init__(self, sh_degree : int, with_mlp: bool = False, mlp_W=128, mlp_D=4, N_a = 32):
    # ... (keep existing code)
    self.active_sh_degree = sh_degree
    self.max_sh_degree = sh_degree  
    self._xyz = torch.empty(0)
    
    # REMOVE THESE LINES:
    # self._features_dc_positive = torch.empty(0)
    # self._features_rest_positive = torch.empty(0)
    # self._features_dc_negative = torch.empty(0)
    # self._features_rest_negative = torch.empty(0)

    # ADD THESE LINES for R=2 low-rank decomposition
    # N = (sh_degree + 1)**2, e.g., 9 for sh_degree=2
    self._u_k1 = torch.empty(0) # Shape: (num_points, N, 1)
    self._v_k1 = torch.empty(0) # Shape: (num_points, N, 1)
    self._u_k2 = torch.empty(0) # Shape: (num_points, N, 1)
    self._v_k2 = torch.empty(0) # Shape: (num_points, N, 1)

    self._albedo = torch.empty(0)
    # ... (keep the rest)
```

**2. 修改 `create_from_pcd`**

我们需要为新的高斯初始化这4个向量。
*   **Rank-1 (Diffuse)**: 我们可以用物理先验来初始化。`v_k1` 应该捕捉余弦项，`u_k1` 应该是各向同性的（只有DC项）。
*   **Rank-2 (Specular)**: 我们可以初始化为小的随机值，让网络自己去学习。

```python
# In class GaussianModel:
def create_from_pcd(self, pcd : BasicPointCloud, spatial_lr_scale : float):
    # ... (keep existing code up to fused_color)
    
    # Physical initialization for Rank-1 (Diffuse Component)
    # v_k1 should represent the cosine lobe, which is dominated by L1 SH bands.
    # Let's initialize it to a simple upward-facing cosine lobe for simplicity.
    num_points = fused_point_cloud.shape[0]
    sh_dim = (self.max_sh_degree + 1) ** 2 # Should be 9
    
    # v_k1: Represents (n dot l), mostly L1 SH
    v_k1_init = torch.zeros(num_points, sh_dim, 1, device="cuda")
    v_k1_init[:, 2, 0] = 1.0 # A simple lobe pointing up along Z for initialization
    
    # u_k1: Represents isotropic diffuse emission, so only DC component is non-zero
    u_k1_init = torch.zeros(num_points, sh_dim, 1, device="cuda")
    u_k1_init[:, 0, 0] = np.pi # Energy conservation for Lambertian

    # Random initialization for Rank-2 (Specular Component)
    v_k2_init = torch.randn(num_points, sh_dim, 1, device="cuda") * 0.01
    u_k2_init = torch.randn(num_points, sh_dim, 1, device="cuda") * 0.01

    self._xyz = nn.Parameter(fused_point_cloud.requires_grad_(True))
    self._albedo = nn.Parameter(albedo.requires_grad_(True))
    self._scaling = nn.Parameter(scales.requires_grad_(True))
    self._rotation = nn.Parameter(rots.requires_grad_(True))
    self._opacity = nn.Parameter(opacities.requires_grad_(True))

    # Add new parameters
    self._u_k1 = nn.Parameter(u_k1_init.requires_grad_(True))
    self._v_k1 = nn.Parameter(v_k1_init.requires_grad_(True))
    self._u_k2 = nn.Parameter(u_k2_init.requires_grad_(True))
    self._v_k2 = nn.Parameter(v_k2_init.requires_grad_(True))

    self.max_radii2D = torch.zeros((self.get_xyz.shape[0]), device="cuda")
```

**3. 彻底重写光照计算函数**

用我们的低秩模型替换原来的`compute_gaussian_rgb`。新函数将返回SH系数，而不是最终的RGB。

```python
# In class GaussianModel:
# DELETE the old compute_gaussian_rgb function.

# ADD this new function:
def compute_radiance_sh(self, sh_env):
    """
    Computes the SH coefficients of the outgoing radiance using R=2 low-rank model.
    
    Args:
        sh_env (Tensor): SH coefficients of the environment light, shape [3, N].
    
    Returns:
        Tensor: SH coefficients of outgoing radiance for each Gaussian, shape [num_points, 3, N].
    """
    # sh_env is [3, N]. Transpose to [N, 3] for dot product.
    sh_env_T = sh_env.T.unsqueeze(0) # Shape: [1, N, 3]
    
    # v vectors are [P, N, 1]. Transpose to [P, 1, N] for dot product.
    v1_T = self._v_k1.transpose(1, 2) # Shape: [P, 1, N]
    v2_T = self._v_k2.transpose(1, 2) # Shape: [P, 1, N]

    # Rank-1 (Diffuse)
    # response_1 = dot(l, v1) -> [P, 1, 3]
    response_1 = torch.bmm(v1_T, sh_env_T.expand(self._v_k1.shape[0], -1, -1))
    # L_o_coeffs_1 = response_1 * u1 -> [P, N, 3]
    L_o_coeffs_1 = self._u_k1 * response_1
    
    # Rank-2 (Specular)
    # response_2 = dot(l, v2) -> [P, 1, 3]
    response_2 = torch.bmm(v2_T, sh_env_T.expand(self._v_k2.shape[0], -1, -1))
    # L_o_coeffs_2 = response_2 * u2 -> [P, N, 3]
    L_o_coeffs_2 = self._u_k2 * response_2

    # Sum contributions and reshape for the rasterizer
    # Result is [P, N, 3] -> transpose to [P, 3, N]
    L_o_total_coeffs = (L_o_coeffs_1 + L_o_coeffs_2).transpose(1, 2)
    
    # We will multiply by albedo later, after SH evaluation in the rasterizer,
    # or we can consider albedo as part of the BRDF and multiply here.
    # For now, let's keep albedo separate and apply it to the final rendered color.
    # The returned SH coefficients represent the BRDF * Irradiance.
    
    return L_o_total_coeffs
```

**4. 更新 `training_setup`**

将新的可学习参数加入优化器。

```python
# In class GaussianModel:
def training_setup(self, training_args):
    # ...
    l = [
        {'params': [self._xyz], 'lr': ..., "name": "xyz"},
        # REMOVE all _features_* parameters
        # {'params': [self._features_dc_positive], ...},
        
        # ADD the new low-rank parameters
        {'params': [self._u_k1], 'lr': training_args.feature_lr, "name": "u1"},
        {'params': [self._v_k1], 'lr': training_args.feature_lr, "name": "v1"},
        {'params': [self._u_k2], 'lr': training_args.feature_lr, "name": "u2"},
        {'params': [self._v_k2], 'lr': training_args.feature_lr, "name": "v2"},

        {'params': [self._opacity], 'lr': ..., "name": "opacity"},
        # ... (keep the rest)
    ]
    # ...
```

**5. 更新 `save_ply`, `load_ply`, `capture`, `restore`, `densification_postfix`, `prune_points` 等**

这是一个比较繁琐但必须的步骤。你需要将所有出现`_features_*`的地方替换为`_u_k1, _v_k1, _u_k2, _v_k2`。例如，在`save_ply`中，你需要为这36个新参数创建新的属性列。在`densify_and_clone`时，需要复制这4个新张量。

---

### 第二步：适配渲染管线 (`gaussian_renderer/__init__.py`)

我们需要修改`render`函数，让它能够接收我们动态计算出的出射光辉SH系数。

```python
# In gaussian_renderer/__init__.py

def render(viewpoint_camera, pc : GaussianModel, pipe, bg_color : torch.Tensor, 
           scaling_modifier = 1.0, override_color = None, override_sh = None, gaussian_mask=None): # ADD override_sh
    """
    Render the scene. 
    ...
    """
    # ... (keep existing code)
    
    # If precomputed colors are provided, use them. Otherwise, if it is desired to precompute colors
    # from SHs in Python, do it. If not, then SH -> RGB conversion will be done by rasterizer.
    pipe.convert_SHs_python = False
    shs = None # CHANGE this
    colors_precomp = None
    if override_color is not None:
        colors_precomp = override_color
    elif override_sh is not None: # ADD THIS BLOCK
        shs = override_sh
    else:
        # This part is the original 3DGS logic, which we are bypassing in our new training loop
        # We can leave it for other scripts that might still use it.
        shs = pc.get_features

    # ... (keep existing code for rasterizer call)
    rendered_image, radii, allmap = rasterizer(
        ...
        shs = shs, # This will now pass our custom SHs
        colors_precomp = colors_precomp,
        ...
    )
    # ... (keep rest of the function)
```

---

### 第三步：修改训练循环 (`train.py`)

现在我们将所有部分串联起来。在训练循环中，我们将调用新的光照函数，并将结果通过新的`override_sh`参数传递给渲染器。

```python
# In train.py, inside the training loop:

for iteration in range(first_iter, opt.iterations + 1):
    # ... (keep existing code for getting camera, env_sh, etc.)

    # DELETE the old unshadowed/shadowed blocks
    # if unshadowed_image_loss_lambda >0:
    #     rgb_precomp_unshadowed, _ = ...

    # ADD the new rendering logic
    # 1. Compute the outgoing radiance SH coefficients using the new R=2 model
    radiance_sh_precomp = gaussians.compute_radiance_sh(sh_env + sh_random_noise)
    
    # 2. Render the image by passing these SH coefficients to the rasterizer
    # Note: We are no longer using the 'shadowed'/'unshadowed' distinction,
    # as our new model inherently handles both.
    render_pkg = render(viewpoint_cam, gaussians, pipe, background, override_sh=radiance_sh_precomp)
    image = render_pkg["render"]
    
    # The rendered image already has SH evaluated. Now we multiply by albedo.
    # To do this cleanly, we can render the albedo separately and multiply.
    albedo_pkg = render(viewpoint_cam, gaussians, pipe, background, override_color=gaussians.get_albedo)
    albedo_map = albedo_pkg["render"]
    
    final_image = torch.clamp(image * albedo_map, 0.0, 1.0)

    # 3. Compute loss against the ground truth image
    Ll1 = l1_loss(final_image, gt_image, mask=mask)
    total_image_loss = (1.0 - opt.lambda_dssim) * Ll1 + opt.lambda_dssim * (1.0 - ssim(final_image, gt_image, mask=mask))
    
    # ... (keep the physical loss calculations if desired, they might need adjustments)

    # The rest of the densification logic might need some tweaks,
    # e.g., viewspace_point_tensor might need to be taken from one of the render calls.
    viewspace_point_tensor, visibility_filter, radii = render_pkg["viewspace_points"], render_pkg["visibility_filter"], render_pkg["radii"]

    # ... (rest of the training loop)
    total_loss = total_image_loss + ... # Add other losses
    total_loss.backward()
```

### 第四步：（可选但推荐）添加正则化损失

为了引导模型学习有意义的分解，可以在`utils/loss_utils.py`中添加新的损失函数，并在`train.py`中调用它们。

```python
# In utils/loss_utils.py

def compute_low_rank_reg_loss(u1, v1, u2, v2):
    # Loss to encourage u1 to be isotropic (only DC)
    loss_diffuse = torch.mean(u1[:, 1:]**2) # Penalize high-frequency components of u1
    
    # Loss to encourage orthogonality between the two bases
    # This helps separate diffuse and specular components
    loss_ortho = (torch.sum(u1 * u2, dim=1)**2).mean() + (torch.sum(v1 * v2, dim=1)**2).mean()
    
    return loss_diffuse, loss_ortho
```

然后在`train.py`的循环中加入这个损失：
```python
# In train.py loop
# ... after computing total_image_loss
loss_diffuse_reg, loss_ortho_reg = compute_low_rank_reg_loss(
    gaussians._u_k1, gaussians._v_k1, gaussians._u_k2, gaussians._v_k2
)
total_loss += 0.01 * loss_diffuse_reg + 0.01 * loss_ortho_reg # Use small weights
```

### 总结

这个实现方案将LumiGauss的模型从一个视图无关的简化PRT，升级为了一个视图相关的、基于低秩分解的PRT模型。
- **核心改变**在于`scene/gaussian_model.py`，你将用4个SH向量替换旧的特征表示，并重写光照计算逻辑。
- **关键适配**在于`train.py`和`gaussian_renderer/__init__.py`，你需要建立一个新的通路，将动态计算的SH系数传递给光栅化器。
- **效果**将是能够渲染出随视角和光照变化的模糊高光，大大提升了材质的表现力和真实感，同时通过低秩分解保持了高效的存储和计算。

完成这些步骤后，你就拥有了一个更强大、更物理的高斯泼溅重光照系统。

# 参数量比较

好的，我们来详细计算一下，从LumiGauss的模型升级到我们提出的R=2低秩分解模型后，每个高斯基元（Gaussian Primitive）的可学习参数量的具体变化。

我们将只关注与光照和材质相关的参数，因为位置、旋转、缩放和不透明度这些几何参数在两个模型中是完全相同的。

---

### 1. LumiGauss 的参数量 (每个高斯)

在LumiGauss的原始设计中，它为每个高斯学习以下与外观相关的参数：

1.  **反照率 (Albedo)**:
    *   它存储为SH DC（0阶）系数。
    *   参数量：**3** 个浮点数 (RGB)。
    *   `_albedo` 属性 (`scene/gaussian_model.py`)。

2.  **传输函数 (Transfer Function)**:
    *   LumiGauss的核心创新是为每个高斯学习一个传输函数 `d_k`，表示为SH系数。为了处理2DGS中法线翻转的问题，它实际上为每个高斯存储了两套传输函数（`positive` 和 `negative`）。
    *   SH阶数：`sh_degree = 2`。
    *   每个传输向量的SH系数数量 `N = (sh_degree + 1)² = (2 + 1)² = 9`。
    *   `_features_dc_positive`: `1` 个DC系数 (这里只存储灰度shadow，所以是1个通道)。
    *   `_features_rest_positive`: `8` 个AC系数。
    *   `_features_dc_negative`: `1` 个DC系数。
    *   `_features_rest_negative`: `8` 个AC系数。
    *   参数量： `(1 + 8) + (1 + 8) = 9 + 9 =` **18** 个浮点数。
    *   *注意：论文提到 `These coefficients correspond to a single channel in practice`，这意味着传输函数是灰度的，所以不需要乘以3。*

**LumiGauss 总参数量 (每个高斯):**
$3 \text{ (Albedo)} + 18 \text{ (Transfer Function)} = \mathbf{21}$ **个浮点数**

---

### 2. R=2 低秩分解模型的参数量 (每个高斯)

在我们提出的新模型中，我们用4个SH向量来表示秩为2的传输矩阵。

1.  **反照率 (Albedo)**:
    *   保持不变，仍然是SH DC系数。
    *   参数量：**3** 个浮点数 (RGB)。

2.  **秩为2的传输矩阵分解**:
    *   我们需要存储4个向量：`u_k1`, `v_k1`, `u_k2`, `v_k2`。
    *   SH阶数：`sh_degree = 2`。
    *   每个向量的维度 `N = (2 + 1)² = 9`。
    *   这些向量需要能够表示彩色的光照效果（例如，高光可能会有颜色），所以它们是三通道的。但是，为了与LumiGauss的单通道传输函数进行公平比较，我们先假设它们也是**单通道**的（即只学习灰度传输）。
    *   参数量 (单通道): $4 \text{ 个向量} \times 9 \text{ 个系数/向量}$ = **36** 个浮点数。

**R=2 低秩模型 总参数量 (每个高斯, 单通道传输):**
$3 \text{ (Albedo)} + 36 \text{ (Rank-2 Transfer)} = \mathbf{39}$ **个浮点数**

---

### 对比分析

| 模型 | 外观参数 | 参数量 (每个高斯) |
| :--- | :--- | :--- |
| **LumiGauss** | Albedo (3) + Transfer Vec (18) | **21** |
| **R=2 低秩模型** | Albedo (3) + Transfer Factors (36) | **39** |

**结论：**

*   **参数量增加了约 86%** (从 21 增加到 39)。
*   虽然参数量增加了，但我们获得了表示**视图相关效果（光泽反射）**的强大能力，这是LumiGauss模型完全无法做到的。
*   这个增加的成本远低于存储一个完整的 `9x9` 传输矩阵（81个参数），后者会导致总参数量达到 `3 + 81 = 84`，是LumiGauss的**4倍**。
*   因此，R=2低秩分解模型在**模型能力**和**参数效率**之间提供了一个非常出色的平衡点。

### 如果考虑彩色传输...

如果我们假设R=2模型中的传输矩阵需要处理彩色光线传输（即每个向量都是RGB三通道的），那么参数量会进一步增加：

*   参数量 (三通道): `4 \text{ 个向量} \times 9 \text{ 个系数/向量} \times 3 \text{ 通道} = 108` 个浮点数。
*   总参数量：`3 (Albedo) + 108 = 111` 个浮点数。

这通常是**没有必要**的。在实践中，更高效的做法是：
1.  学习一个**单通道（灰度）的传输矩阵**，得到出射光辉的**强度**的SH系数。
2.  学习一个独立的、低维度的**彩色反射率**（可能也是SH表示），然后将其与计算出的灰度光辉相乘。

因此，**将39个参数与21个参数进行比较是更现实和公平的**。升级的代价是为每个高斯基元增加18个浮点数的存储，以此换来模拟镜面反射的能力。

# 参数量/计算量相比于lumigauss变化？根据lumigauss代码实现为准

好的，我们来精确地分析一下，在 LumiGauss 的代码实现基础上，将模型升级为 R=2 低秩分解方案后，参数量和计算量的具体变化。

我们将以3阶球谐函数（SH Degree=2，总共 `(2+1)² = 9` 个系数）为基准进行计算，这与 LumiGauss 的设定一致。

---

### 1. 参数量 (存储成本) 变化

参数量主要体现在每个高斯基元 (Gaussian primitive) 需要存储的、与光照相关的可学习参数上。

#### LumiGauss 的实现 (`scene/gaussian_model.py`)

LumiGauss 为了处理法线翻转（即高斯始终朝向相机），为每个高斯存储了两套传输函数（SH系数向量）。

*   `self._features_dc_positive`: `[num_points, 1, 3]` -> 转置后为 `[num_points, 3, 1]`。每个高斯有3个浮点数（RGB的DC项）。
*   `self._features_rest_positive`: `[num_points, 8, 3]` -> 转置后为 `[num_points, 3, 8]`。每个高斯有 `3 * 8 = 24` 个浮点数（RGB的AC项）。
*   `self._features_dc_negative`: 同上，3个浮点数。
*   `self._features_rest_negative`: 同上，24个浮点数。

**总参数量 (LumiGauss)**：
每个高斯需要存储 `(3 + 24) + (3 + 24) = 54` 个浮点数来表示其传输函数 `d_k`。

#### R=2 低秩分解方案 (我们的新实现)

我们用4个SH系数向量来近似传输矩阵 `T_k`。因为我们的模型是视图相关的，它隐式地处理了法线方向，所以我们不再需要为正反面存储两套参数。一个传输矩阵就足够了。

*   `self._u_k1`: `[num_points, 9, 1]`。每个高斯 `9` 个浮点数。
*   `self._v_k1`: `[num_points, 9, 1]`。每个高斯 `9` 个浮点数。
*   `self._u_k2`: `[num_points, 9, 1]`。每个高斯 `9` 个浮点数。
*   `self._v_k2`: `[num_points, 9, 1]`。每个高斯 `9` 个浮点数。

**总参数量 (R=2 低秩方案)**：
每个高斯需要存储 `9 + 9 + 9 + 9 = 36` 个浮点数。

#### 结论：参数量变化

| 模型 | 每个高斯的参数量 (浮点数) | 变化 |
| :--- | :--- | :--- |
| **LumiGauss** | 54 | - |
| **R=2 低秩分解** | 36 | **减少 33.3%** |

**结果出乎意料但非常有利：** 尽管我们的新模型在功能上（视图相关）比LumiGauss（视图无关）强大得多，但由于我们用一个统一的、更紧凑的数学模型（低秩分解）代替了原来为正反面存储两套参数的“蛮力”方法，**每个高斯的参数量反而减少了三分之一**。这是一个巨大的胜利。

---

### 2. 计算量 (前向传播成本) 变化

计算量主要体现在训练循环中为每个高斯计算最终颜色（或传递给光栅化器的属性）的成本。

#### LumiGauss 的实现 (`scene/gaussian_model.py` 的 `compute_gaussian_rgb`)

LumiGauss 的计算分为 "shadowed" 和 "unshadowed" 两种模式。我们分析更复杂的 "shadowed" 模式，因为它与 PRT 的概念最接近。

1.  **`get_features`**: 根据 `multiplier` 向量进行一次 `torch.where` 操作，从两套SH系数中选择一套。这是一个内存操作，计算成本很低。
2.  **`eval_sh_shadowed`**: 核心计算是一个点积。
    *   `einops.einsum(shs_gauss, sh_scene, 'b i j, i j->b i')`
    *   这里 `shs_gauss` 是 `[P, 1, 9]` (只考虑单通道阴影)，`sh_scene` 是 `[3, 9]`。
    *   它计算的是 `P` 个 `1x9` 向量与 `3x9` 矩阵的乘积，得到 `P x 3` 的结果。
    *   对于每个高斯的每个颜色通道，这是一个 **9维向量点积**。
    *   总计算量：`P * 3 * (9次乘法 + 8次加法)`。

**总计算量 (LumiGauss)**：
每个高斯大约需要 `3 * 9 = 27` 次乘法和 `3 * 8 = 24` 次加法来得到最终的`intensity`。

#### R=2 低秩分解方案 (我们的新实现)

我们的新模型在光照计算 (`compute_radiance_sh`) 和光栅化 (`EvaluateSH`) 两个阶段都有计算。

**1. `compute_radiance_sh` (在CPU/GPU上，光栅化之前)**:
    a.  **计算 `response_1`**: 一个 `[P, 1, 9]` 向量批次与一个 `[P, 9, 3]` 向量批次的 `bmm`。这等效于 `P` 次 `1x9` 与 `9x3` 的矩阵乘法，结果是 `P x 1 x 3`。
        *   每个高斯需要 `9 * 3 = 27` 次乘法和 `8 * 3 = 24` 次加法。
    b.  **计算 `L_o_coeffs_1`**: `P` 次标量-向量乘法。结果是 `[P, 9, 3]`。
        *   每个高斯需要 `9 * 3 = 27` 次乘法。
    c.  **计算 `response_2` 和 `L_o_coeffs_2`**: 与上面完全相同。
    d.  **合并**：`P` 次向量加法。
        *   每个高斯需要 `9 * 3 = 27` 次加法。

    *   **此阶段总计**：每个高斯需要 `(27 + 27) * 2 = 108` 次乘法和 `24 * 2 + 27 = 75` 次加法，来计算出射光辉的SH系数。

**2. `EvaluateSH` (在光栅化器中，GPU上)**:
    *   光栅化器需要根据观察方向 `ωo` 对上一步计算出的SH系数 `L_o_total_coeffs_k` 进行求值。
    *   对于3阶SH，求值过程需要计算9个SH基函数的值，然后与9个系数进行点积。
    *   这个计算对每个颜色通道都要做一次。
    *   总计算量：`P * 3 * (9次乘法 + 8次加法)`（与LumiGauss的点积计算量相同）。

#### 结论：计算量变化

| 模型/阶段 | 每个高斯的计算量 (大约) |
| :--- | :--- |
| **LumiGauss** | `~27` 乘法, `~24` 加法 |
| **R=2 低秩分解** | |
| - 光照计算 | `~108` 乘法, `~75` 加法 |
| - SH求值 | `~27` 乘法, `~24` 加法 |
| - **总计** | **`~135` 乘法, `~99` 加法** |

**结果分析：**
新模型的计算量大约是 LumiGauss 模型的 **4-5倍**。
*   **LumiGauss** 极其高效，因为它只做了一次点积就得到了最终颜色。
*   **我们的模型** 需要做两次类似点积的操作（计算`response_1/2`），两次向量缩放，一次向量加法，最后还要在光栅化阶段再做一次SH求值。

---

### 综合评估

| 方面 | 变化 | 原因与影响 |
| :--- | :--- | :--- |
| **参数量** | **减少 33.3%** | 新模型用一个统一、紧凑的数学表示代替了为正反面存储两套参数的冗余方法。**这对内存和模型大小非常有利。** |
| **计算量** | **增加 4-5 倍** | 新模型引入了视图相关的计算，其数学过程（矩阵-向量乘法）比简单的点积更复杂。**这会影响训练速度和实时渲染帧率，但现代GPU完全可以承受。** |
| **功能/效果** | **巨大提升** | 从只能处理漫反射+阴影，升级为可以处理**漫反射+阴spired+模糊高光**。这是从一个基础模型到一个功能完备的PBR模型的关键跨越。 |

**最终结论：**
我们用**显著增加的计算量**和**显著减少的参数量**，换来了**模型表达能力的巨大飞跃**。这是一个非常值得的权衡，因为它将 LumiGauss 的适用范围从特定的哑光场景扩展到了更普遍、更真实的PBR场景，同时还优化了内存占用。


